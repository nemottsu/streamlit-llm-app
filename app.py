from dotenv import load_dotenv

load_dotenv()

# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI Ã— LangChain Ã— Streamlit ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª
# å°‚é–€å®¶ï¼ˆé‡èœ / æœç‰© / ä¸€èˆ¬AIï¼‰åˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½ä»˜ã
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
# os.system("pip install streamlit==1.41.1 python-dotenv==1.0.0")
# os.system("pip install langchain==0.3.0 openai==1.47.0 langchain-community==0.3.0 langchain-openai==0.2.2 httpx==0.27.2")

from typing import Literal

import streamlit as st
from dotenv import load_dotenv

# LangChainé–¢é€£
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage


# â”€â”€ åˆæœŸè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()  # .env ã‹ã‚‰ OPENAI_API_KEY ã‚’èª­ã¿è¾¼ã‚€

st.set_page_config(
    page_title="å°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆï¼ˆé‡èœ / æœç‰© / ä¸€èˆ¬ï¼‰",
    page_icon="ğŸ¥¦",
    layout="centered"
)

# OpenAI API Key ç¢ºèª
if not os.getenv("OPENAI_API_KEY"):
    st.error("ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# LLMï¼ˆLangChainçµŒç”±ã§OpenAIã«æ¥ç¶šï¼‰
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.5)


# â”€â”€ å½¹å‰²ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPTS = {
    "ä¸€èˆ¬çš„ãªè³ªå•ã«å›ç­”ã™ã‚‹AI": (
        "ã‚ãªãŸã¯ä¸å¯§ã§èª å®Ÿãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æœªçŸ¥ã®ç‚¹ã¯æ­£ç›´ã«è¿°ã¹ã€"
        "å¿…è¦ã«å¿œã˜ã¦å‰æã‚„åˆ¶ç´„ã‚’æ˜ç¢ºåŒ–ã—ã€ç°¡æ½”ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    ),
    "é‡èœ": (
        "ã‚ãªãŸã¯é‡èœåˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚æ ½åŸ¹ãƒ»å“ç¨®ãƒ»æ „é¤Šãƒ»ä¿å­˜ãƒ»èª¿ç†ã«é–¢ã™ã‚‹æœ€æ–°çŸ¥è¦‹ã‚’è¸ã¾ãˆã€"
        "ç§‘å­¦çš„æ ¹æ‹ ã‚„å®Ÿå‹™çš„ãªã‚³ãƒ„ã‚’äº¤ãˆãªãŒã‚‰æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    ),
    "æœç‰©": (
        "ã‚ãªãŸã¯æœç‰©åˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚å“ç¨®ç‰¹æ€§ãƒ»æ—¬ãƒ»ç”£åœ°ãƒ»è¿½ç†Ÿãƒ»ä¿å­˜ãƒ»æ „é¤Šãƒ»åŠ å·¥ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’ç”¨ã„ã€"
        "æ ¹æ‹ ã¨ã¨ã‚‚ã«æ—¥æœ¬èªã§æ˜å¿«ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    ),
}


# â”€â”€ åˆ†é‡é–¢é€£èªã«ã‚ˆã‚‹ç°¡æ˜“åˆ¤å®šï¼ˆã€Œç„¡é–¢ä¿‚ãªã‚‰ä¸€èˆ¬AIã€å¯¾å¿œï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VEG_KEYWORDS = {"é‡èœ", "ã‚­ãƒ£ãƒ™ãƒ„", "ã«ã‚“ã˜ã‚“", "ãƒˆãƒãƒˆ", "ãã‚…ã†ã‚Š", "ã»ã†ã‚Œã‚“è‰", "ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼", "å¤§æ ¹", "ç‰ã­ã", "ãƒ¬ã‚¿ã‚¹", "ãƒŠã‚¹"}
FRU_KEYWORDS = {"æœç‰©", "ãƒ•ãƒ«ãƒ¼ãƒ„", "ãƒªãƒ³ã‚´", "ã¿ã‹ã‚“", "ã‚ªãƒ¬ãƒ³ã‚¸", "ãƒãƒŠãƒŠ", "ã‚¤ãƒã‚´", "ã¶ã©ã†", "æ¡ƒ", "æ¢¨", "ãƒ‘ã‚¤ãƒŠãƒƒãƒ—ãƒ«", "ãƒãƒ³ã‚´ãƒ¼"}

def _looks_related_to(role: Literal["é‡èœ", "æœç‰©"], text: str) -> bool:
    t = text.lower()
    if role == "é‡èœ":
        return any(k in t for k in VEG_KEYWORDS)
    if role == "æœç‰©":
        return any(k in t for k in FRU_KEYWORDS)
    return True


# â”€â”€ LLMå¿œç­”é–¢æ•°ï¼ˆè¦ä»¶ï¼šå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨é¸æŠå€¤ã‚’å¼•æ•°ã«å–ã‚‹ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_llm(user_text: str, role: Literal["ä¸€èˆ¬çš„ãªè³ªå•ã«å›ç­”ã™ã‚‹AI", "é‡èœ", "æœç‰©"]) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å½¹å‰²ã«åŸºã¥ãã€LLMã‹ã‚‰ã®å›ç­”ã‚’è¿”ã™
    """
    # ç„¡é–¢ä¿‚ãªè³ªå•ã¯è‡ªå‹•ã§ã€Œä¸€èˆ¬AIã€ã«åˆ‡ã‚Šæ›¿ãˆ
    effective_role = role
    if role in ("é‡èœ", "æœç‰©") and not _looks_related_to(role, user_text):
        effective_role = "ä¸€èˆ¬çš„ãªè³ªå•ã«å›ç­”ã™ã‚‹AI"

    system_prompt = SYSTEM_PROMPTS[effective_role]

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_text),
    ]

    # LangChain ã‚µãƒ³ãƒ—ãƒ«æº–æ‹ 
    result = llm(messages)
    return result.content


# â”€â”€ Streamlit UI æ§‹ç¯‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ¥¦ å®¶åº­èœåœ’ãƒãƒ£ãƒƒãƒˆï¼ˆé‡èœ / æœç‰© ï¼‰")
st.caption("LangChain Ã— OpenAI Ã— Streamlit / GitHub")

with st.expander("â„¹ï¸ ã‚¢ãƒ—ãƒªã®æ¦‚è¦ã¨ä½¿ã„æ–¹", expanded=True):
    st.markdown(
        """
### ğŸ§­ ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦
- OpenAIã®LLMã‚’LangChainçµŒç”±ã§åˆ©ç”¨ã™ã‚‹ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã§ã™ã€‚
- ã€Œé‡èœã€ã€Œæœç‰©ã€ã®2ç¨®é¡ã®å½¹å‰²ã‚’é¸ã¹ã¾ã™ã€‚
- å…¥åŠ›å†…å®¹ãŒåˆ†é‡ã«ç„¡é–¢ä¿‚ãªå ´åˆã¯ã€è‡ªå‹•çš„ã«ä¸€èˆ¬AIãŒå›ç­”ã—ã¾ã™ã€‚

### ğŸ§‘â€ğŸ’» ä½¿ã„æ–¹
1. å›ç­”å½¹å‰²ã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠ  
2. ä¸‹ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ã‚’ã‚¯ãƒªãƒƒã‚¯  
        """
    )

# å›ç­”AIã®é¸æŠ
role = st.radio(
    "å›ç­”ã™ã‚‹AIã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
    # options=["ä¸€èˆ¬çš„ãªè³ªå•ã«å›ç­”ã™ã‚‹AI", "é‡èœ", "æœç‰©"],
    options=["é‡èœ", "æœç‰©"],    
    index=0,
    horizontal=True,
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form(key="chat_form", clear_on_submit=False):
    user_text = st.text_area(
        "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
        height=150,
        placeholder="ä¾‹ï¼šã‚­ãƒ£ãƒ™ãƒ„ã®ä¿å­˜æ–¹æ³•ã¯ï¼Ÿ / ã‚Šã‚“ã”ã®è¿½ç†Ÿã¯å¿…è¦ï¼Ÿ / Pythonã®foræ–‡ã®æ›¸ãæ–¹ã¯ï¼Ÿ ãªã©",
    )
    submitted = st.form_submit_button("é€ä¿¡")

# é€ä¿¡ãƒœã‚¿ãƒ³å‡¦ç†
if submitted:
    if not user_text.strip():
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
        try:
            answer = ask_llm(user_text=user_text, role=role)
            st.markdown("---")
            st.markdown(f"**é¸æŠã•ã‚ŒãŸå½¹å‰²ï¼š** `{role}`")
            st.markdown("#### ğŸ’¬ å›ç­”")
            st.write(answer)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

